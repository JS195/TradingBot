{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the API\n",
    "\n",
    "API = \"api-fxpractice.oanda.com\"\n",
    "STREAM_API = \"stream-fxpractice.oanda.com\"\n",
    "ACCESS_TOKEN = \"06a31b21abc8fb4cbe9bbd8c5b7b1f4e-260aefea008b878b6bffbfebafc84b9f\"\n",
    "ACCOUNT_ID = \"101-004-26291813-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the nescessary data\n",
    "\n",
    "# Time format is year, month, day\n",
    "from_time = time.mktime(pd.to_datetime(\"2023-07-1-00-00-00\").timetuple())\n",
    "to_time = time.mktime(pd.to_datetime(\"2023-07-10-00-00-00\").timetuple())\n",
    "\n",
    "header = {\"Authorization\": \"Bearer \" + ACCESS_TOKEN}\n",
    "# Granularity is limited for the amount of data available, no more than 3000 entries give or take\n",
    "query = {\"from\": from_time, \"to\": to_time, \"granularity\": \"M5\"}\n",
    "\n",
    "INSTRUMENT = \"XAU_GBP\"\n",
    "CANDLES_PATH = f\"/v3/accounts/{ACCOUNT_ID}/instruments/{INSTRUMENT}/candles\"\n",
    "\n",
    "response = requests.get(\"https://\" + API + CANDLES_PATH, headers=header, params=query)\n",
    "\n",
    "def json_to_pd(json):\n",
    "    json_file = json.json()\n",
    "    price_json = json_file[\"candles\"]\n",
    "    times = []\n",
    "    close_price, high_price, low_price, open_price = [], [], [], []\n",
    "\n",
    "    for candle in price_json:\n",
    "        times.append(candle[\"time\"])\n",
    "        close_price.append(float(candle[\"mid\"][\"c\"]))\n",
    "        high_price.append(float(candle[\"mid\"][\"h\"]))\n",
    "        low_price.append(float(candle[\"mid\"][\"l\"]))\n",
    "        open_price.append(float(candle[\"mid\"][\"o\"]))\n",
    "    \n",
    "    dataframe = pd.DataFrame({\"close\": close_price, \"high\": high_price, \"low\": low_price, \"open\": open_price})\n",
    "    dataframe.index = pd.to_datetime(times)\n",
    "    return dataframe\n",
    "\n",
    "get_data = json_to_pd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Calculate the percentage change of the data\n",
    "def calculate_percentage_change(data):\n",
    "    data['open'] = data['open'].pct_change()\n",
    "    data['high'] = data['high'].pct_change()\n",
    "    data['low'] = data['low'].pct_change()\n",
    "    data['close'] = data['close'].pct_change()\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "percent_data = calculate_percentage_change(get_data)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "dataframe_scaled = pd.DataFrame(scaler.fit_transform(percent_data), columns=percent_data.columns, index=percent_data.index)\n",
    "\n",
    "# Train, test and validation split\n",
    "train_end = int(0.8 * len(dataframe_scaled))\n",
    "val_end = int(0.9 * len(dataframe_scaled))\n",
    "\n",
    "df_train = dataframe_scaled.iloc[:train_end]\n",
    "df_val = dataframe_scaled.iloc[train_end: val_end]\n",
    "df_test = dataframe_scaled.iloc[val_end:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introtoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
